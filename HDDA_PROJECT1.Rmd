---
title: "Project_Group1: High Dimension HDDA"
output:
  html_document:
  
---

## 1) Introduction

This project analyzes student behavior data using descriptive statistics, correlation analysis, Principal Component Analysis (PCA), and regression modeling. The aim is to understand the relationships between phone usage, social network time, happiness, walking distance, and Instagram ratio.


##2. Dataset Description

The dataset contains 5 quantitative variables and:

**Phone**: minutes per day on phone.

**SocialNetworks**: minutes per day on social networks.

**Happiness**: score from 1 to 10.

**Walk**: kilometers walked per day.

**InstagramRatio**: ratio of followers to following.

# Import libraries

```{r setup, include=FALSE}

library(FactoMineR)
library(factoextra)
library(corrplot)
library(ggplot2)
library(dplyr)
```

We need these libraries to make plots, analyze correlations, and clean the dataset.

# Partie II-1 : Importation des données et ACP

## Etape 1: Importation et description des données
```{r}
dataset <- read.csv(file = "HDDAdataexam26.csv",
                    header = TRUE, sep = ";",  dec = ",")
dataset
```

```{r}
# Structure des données
str(dataset)

# Résumé statistique
summary(dataset)
```
**Interprétation:**
-The dataset of QIMS students  containt only the quantitive variable and 369 individuals, 5 variables

- **Phone** :Most students use phone between 10 and 180 minutes. One extreme value = 1440 minutes (24h).

- **SocialNetworks** : Similar to phone time
- **Happiness** :  Most scores are between 7 and 8.
- **Walk** : Some students walk up to 20 km (very active).
- **InstagramRatio** : One extreme value = 51 (many followers compared to following).


#Step 3 – Check missing values
We check if there are missing values before PCA.

```{r}
# Nombre de valeurs manquantes par variable
Nombre <- colSums(is.na(dataset))

# Proportion de valeurs manquantes
Proportion <- Nombre / nrow(dataset)

# Tableau final
table_na <- data.frame(Nombre, Proportion)
table_na


```

##Interpretation:  
No missing values,we can continue PCA

#Step 4 – Remove duplicates
Duplicates can bias analysis. We remove them.
```{r}
# Afficher toutes les lignes dupliquées (première + répétitions)
dataset[duplicated(dataset) | duplicated(dataset, fromLast = TRUE), ]
```

```{r}
# Compter combien de fois chaque ligne apparaît
table(duplicated(dataset))

# Supprimer les doublons si nécessaire
dataset<- dataset[!duplicated(dataset), ]

# Afficher toutes les lignes dupliquées (première + répétitions)
dataset[duplicated(dataset) | duplicated(dataset, fromLast = TRUE), ]



```


### Step 5 – Boxplots of variables
Boxplots show distribution and extreme values.

```{r}
# Afficher 5 graphiques sur 1 colonne ou 5 colonnes
par(mfrow = c(1,5))  # 1 ligne, 5 colonnes

# Boxplots
boxplot(dataset$Phone, main = "Phone", col = "lightblue", ylab = "Minutes")
boxplot(dataset$SocialNetworks, main = "SocialNetworks", col = "pink", ylab = "Minutes")
boxplot(dataset$Happiness, main = "Happiness", col = "lightgreen", ylab = "Score")
boxplot(dataset$Walk, main = "Walk", col = "orange", ylab = "Km")
boxplot(dataset$InstagramRatio, main = "InstagramRatio", col = "purple", ylab = "Ratio")

par(mfrow = c(1,1))

```
# Interpretation:
Phone and InstagramRatio show strong outliers, reflecting extreme behaviors.


## Step 6 – Center and reduce data
When we do PCA, the data must be centered and reduced.

- Centering means subtracting the mean of each variable. After this, the mean of each variable = 0.
- Reducing (standardizing) means dividing by the standard deviation. After this, the variance of each variable = 1.
- we use PCA directly on raw data, variables with large numerical values (like Phone minutes or InstagramRatio) will dominate the analysis. The PCA would mainly reflect those variables, and the others would be almost ignored

- PCA requires all variables to have the same weight

```{r}
# Centrer et réduire les données
scale_center_dataset <- scale(dataset,center = TRUE,scale=TRUE)

head(scale_center_dataset)

```
#Step 7 – Correlation matrix
We check relationships between variables.

```{r}
# Calculer la matrice de corrélation
matrice_correlation <- cor(scale_center_dataset)

matrice_correlation
# Corrplot avec légende propreD
corrplot(matrice_correlation,
         method = "color",
         type = "upper",         
         order = "hclust",        
         tl.col = "black",        
         tl.srt = 45,             
         addCoef.col = "black",   
         number.cex = 0.8,  
         cl.pos = "r",            
         cl.cex = 1.2             


)

```
## interpretation

According to the results  the Phone and SocialNetworks are strongly positively correlated then we supposse that students who use phone a lot also use social networks a lot.


## Step 8 –  Principal Component Analysis (PCA)

PCA reduces dimensions and finds main axes.

```{r}
# Realisons l'ACP
res.pca <- PCA(scale_center_dataset, graph =FALSE)

print(res.pca)
```
### Step: choice of principal components

### 1)Eigenvalues
Eigenvalues show how much variance (information) each principal component explains.

```{r}
eig.val=get_eigenvalue(res.pca)
eig.val

```

```{r}
eig_arrondi <- round(eig.val, 2)
print(eig_arrondi)
```
#interpretation : 

Dim.1 explains 35% of variance, Dim.2 23%. The first two dimensions already summarize 58% of student behaviors.

## How to choose the number of axes?:

## Method 1 : Kaiser rule (eigenvalue > 1
keep Dim1 and Dim2 (eigenvalue > 1).

## methode 2 : Elbow rule

look at the graph of eigenvalues and stop at the “bend”.


```{r}
fviz_eig(res.pca , addlabels = TRUE)
```

### methode3:Cumulative variance: keep enough components to explain 70–80% of total variance.

Find the number of dimensions needed to reach 75% (defined threshold).
Dim.1 + Dim.2 = 57.88% (not enough)
Dim.1 + Dim.2 + Dim.3 = 76.68% (threshold reached)
 
## interpreattion :
So we keep 2 components 


#  Variables Analysis
## Step 9 – Variables correlation circle

here is to shows how variables are related to principal components.

```{r}
# Créeons  le graphique du cercle de corrélation
fviz_pca_var(res.pca, 
             col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE, 
             title = "Corrélation  circle of Variables")
```


1) Axe Dim1 (35 % de variance)
he arrows Phone and SocialNetworks point strongly to the right. This means these two variables are highly correlated and explain most of the students’ digital behavior.
2) Axe Dim2 (23 % de variance)

The arrows Happiness and Walk go upwards. This shows they are linked together and define another axis: well-being and physical activity.


```{r}
fviz_pca_var(res.pca, 
             col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE, 
             title = "Cercle de Corrélation des Variables")
```

# interpretation 

# - PC1 (Dim 1) explains about 35% of the variance.  
# - 'Phone' and 'SocialNetworks' are very close and positively correlated with axis 1.  
# - This means that screen time is mainly linked to the use of social networks.  

##Step 10 – Individuals projection
We project students on PCA axes

```{r}
fviz_pca_ind(res.pca, col.ind="cos2") +
  scale_color_gradient2(low="blue", mid="white", high="red", midpoint=0.50)

# Coordonnées des individus
head(res.pca$ind$coord)

# Cos 2 des individus
head(res.pca$ind$cos2)
#Contribution des individus
head(res.pca$ind$contrib)

```

### Contributions  of variables on axe 1 (PC1)
```{r}
# Contributions of variables to PC1"
fviz_contrib(res.pca, choice = "var", axes = 1, top = 3)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
```



```{r}
# Cosinus carré des variables sur la première composante principale (PC1)
fviz_cos2(res.pca, choice = "var", axes = 1, top = 10) +
  ggtitle("Qualité de la représentation des variables sur la PC1 (cos²)")

# Cosinus carré des variables sur la deuxième composante principale (PC2)
fviz_cos2(res.pca, choice = "var", axes = 2, top = 10) +
  ggtitle("Qualité de la représentation des variables sur la PC2 (cos²)")
```

We show variables with cos² > 0.5 to see which are well represented by the axes. This means they are close to the circle and explained by PCA. In real life, this shows that Phone and SocialNetworks are the best indicators of digital behavior of QIMS students.


```{r}
fviz_pca_ind(res.pca,  col.ind="cos2") +
scale_color_gradient2(low="blue", mid="white", 
                      high="red", midpoint=0.50)+
  theme_minimal()
```

```{r}
# Filtrer les individus avec cos² > 50%
ind_cos2 <- apply(res.pca$ind$cos2, 1, max) > 0.5

# Filtrer les variables avec cos² > 50%
var_cos2 <- apply(res.pca$var$cos2, 1, max) > 0.5

#  combiné des individus et des variables
fviz_pca_biplot(res.pca,
                select.ind = list(cos2 = 0.5), 
                select.var = list(cos2 = 0.5), 
                repel = TRUE,                  
                title = "Biplot of Individuals and Variables (cos² > 50%)",
                col.ind = "blue",             
                col.var = "red")              

```


## PARTIE II Regression analysis

## Question 1 a)

## Create dummy variables
We want to study students with very low or very high Instagram ratios

```{r}
# 1) Build the following variables and add them to the dataset
dataset$LowInstagram <- ifelse(dataset$InstagramRatio < 0.5, 1, 0) 
dataset$HighInstagram <- ifelse(dataset$InstagramRatio > 2, 1, 0)  
head(dataset)
```

```{r}
# Check structure and frequency 
str(dataset) 
table(dataset$LowInstagram) 
table(dataset$HighInstagram)
```
#interpretation:

These variables distinguish two student profiles: 
# - LowInstagram = 1: students who follow many accounts but have few followers.This shows a "consumer" profile, not influential. 
# - HighInstagram = 1: students with many followers compared to following.  This shows an "influencer" or "popular" profile.


```{r}
# 2) Multiple linear regression
model_reg <- lm(Phone ~ SocialNetworks + Happiness + Walk + LowInstagram + HighInstagram, data = dataset)
summary(model_reg)


```
## interpretation:

The global test shows the model is very useful to explain phone time. The strongest factor is SocialNetworks (very significant): more social networks then more phone time. Happiness is also significant but negative: happier students use their phone less, showing a protective effect. Walk is not significant: physical activity does not clearly reduce phone time. LowInstagram and HighInstagram show small trends (p-values near 0.05), meaning Instagram profile may play a role, but the effect is not statistically confirmed.

The regression model is **statistically strong**.

Global F-test: p-value = 4.28e-58  it means that the model is highly significant and useful.

Adjusted R² = 0.529 that the model explains about 53% of the variance in phone time.

SocialNetworks: positive effect (+0.91, p < 0.001) each extra minute on social networks adds almost one minute of phone use.

Happiness: negative effect (-7.39, p = 0.013) and higher happiness scores reduce phone time.

# 3) ANOVA – Usefulness of the model

```{r}
anova_result <- anova(model_reg)
print(anova_result)

# Global F-test
f_stat <- summary(model_reg)$fstatistic
p_value_global <- pf(f_stat[1], f_stat[2], f_stat[3], lower.tail = FALSE)
cat("\nGlobal F-test p-value:", p_value_global, "\n")

```

# 4) Significance of SocialNetworks

```{r}
coef_summary <- summary(model_reg)$coefficients
p_value_social <- coef_summary["SocialNetworks", "Pr(>|t|)"]
cat("P-value for SocialNetworks:", p_value_social, "\n")


```
# interpretation :
SocialNetworks is highly significant (p-value < 0.05).
# This confirms that social networks time is a major factor of smartphone addiction.
# In real life, students spending time on Instagram, Facebook or WhatsApp
# also increase their overall screen 

# 5) Impact of Happiness
```{r}

coef_happiness <- coef_summary["Happiness", "Estimate"]
p_value_happiness <- coef_summary["Happiness", "Pr(>|t|)"]

cat("Coefficient of Happiness:", coef_happiness, "\n")
cat("P-value for Happiness:", p_value_happiness, "\n")


```
#interpretation:

Happiness has a negative and significant coefficient.
This means that happier students spend less time on their phone.
student satisfied with social or academic life is less dependent on the screen.


# 6) Predictions for Students A and B
```{r}

student_A <- data.frame(SocialNetworks = 120, Happiness = 4, Walk = 15, LowInstagram = 0, HighInstagram = 1)
student_B <- data.frame(SocialNetworks = 120, Happiness = 4, Walk = 15, LowInstagram = 1, HighInstagram = 0)

Phone_A <- predict(model_reg, newdata = student_A)
Phone_B <- predict(model_reg, newdata = student_B)

cat("Phone_student(A) - InstagramRatio=2.1:", Phone_A, "minutes\n")
cat("Phone_student(B) - InstagramRatio=0.4:", Phone_B, "minutes\n")

# Interpretation:
# FR : Les étudiants A et B ont les mêmes comportements (réseaux sociaux, bonheur, marche),
# mais leurs temps prédits diffèrent à cause du ratio Instagram.
# Cela montre que la popularité sur Instagram influence aussi l’addiction au smartphone.
#
# EN : Students A and B have the same behaviors (social networks, happiness, walking),
# but their predicted phone times differ because of Instagram ratio.
# This shows that Instagram popularity also influences smartphone addiction.

```
#interpreation :
Students A and B have the same behaviors (social networks, happiness, walking), # but their predicted phone times differ because of Instagram ratio. 
This shows that Instagram popularity also influences smartphone addiction.
 the Instagram popularity changes smartphone use: popular students use their phone less, while less popular students use it more.
 
 
# Question 7: Backward stepwise regression

```{r}

cat("\n initial model :\n")
print(summary(model_reg)$coefficients)

# Étape par étape - suppression du prédicteur le moins significatif
current_model <- model_reg
step_count <- 1

repeat {
  coef_table <- summary(current_model)$coefficients
  # Exclure l'intercept
  predictors <- rownames(coef_table)[-1]
  p_values <- coef_table[predictors, "Pr(>|t|)"]
  
  # Trouver le prédicteur avec la plus grande p-value
  max_p_value <- max(p_values)
  
  # Si tous les prédicteurs sont significatifs, on s'arrete
  if(max_p_value < 0.05) {
    cat("\nTous les prédicteurs restants sont significatifs au seuil de 5%\n")
    break
  }
  
  # Supprimer le prédicteur le moins significatif
  to_remove <- names(which.max(p_values))
  cat("\n Étape", step_count, " \n")
  cat("Suppression de:", to_remove, "(p-value =", max_p_value, ")\n")
  
  # Mettre à jour la formule
  formula_str <- as.character(formula(current_model))
  new_formula <- as.formula(paste(formula_str[2], "~", 
                                  paste(predictors[predictors != to_remove], 
                                        collapse = " + ")))
  
  current_model <- lm(new_formula, data = dataset)
  print(summary(current_model)$coefficients)
  
  step_count <- step_count + 1
}

# Modèle final après backward stepwise
model_backward <- current_model
cat("\n MODÈLE FINAL AFTER  BACKWARD STEPWISE \n")
summary(model_backward)

```

#interpretation :

The backward model keeps only significant variables: SocialNetworks, Happiness, and HighInstagram. Smartphone use in AIMS students is mainly explained by social networks (increase phone time), reduced by happiness (protective effect), and influenced by Instagram popularity (highly followed students spend less time on phone)

```{r}
# 8) Compare models
cat("Adjusted R² (full model):", summary(model_reg)$adj.r.squared, "\n")
cat("Adjusted R² (backward model):", summary(model_backward)$adj.r.squared, "\n")

```

# Interpretation:
The difference between the two models is very small (0.5288 vs 0.5275). This means removing non-significant variables did not reduce the model’s explanatory power. The backward model is simpler (fewer variables) but still almost as strong as the full model.

# 9 & 10) Predictions for new students
```{r}

new_student_9 <- data.frame(SocialNetworks = 30, Happiness = 8, Walk = 2, LowInstagram = 0, HighInstagram = 1)
prediction_9 <- predict(model_backward, newdata = new_student_9)

new_student_10 <- data.frame(SocialNetworks = 30, Happiness = 8, Walk = 2, LowInstagram = 1, HighInstagram = 0)
prediction_10 <- predict(model_backward, newdata = new_student_10)

cat("Predicted Phone time (InstagramRatio=2.1):", prediction_9, "minutes\n")
cat("Predicted Phone time (InstagramRatio=0.4):", prediction_10, "minutes\n")


```

# Interpretation:
 The model predicts that two students with the same habits (social networks, happiness, walking)
will have different screen times depending on their Instagram profile.
This illustrates the importance of social networks in real life of QIMS students.


#CONCLUSION 

Regression analysis shows that: 
- Social networks strongly increase phone time. 
- Happiness reduces this time (protective effect). 
- Instagram ratio plays an important social role. The backward model is the most reliable because it keeps only significant variables. This analysis

